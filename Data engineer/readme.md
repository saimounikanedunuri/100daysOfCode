Summary
1. Python
2. Hadoop Ecosystem
      - Apache Spark ( Preprocessing Framework)
      - HDFS (File Storage) - little 
3. Storage System 
     - SQL (RDBMS)
4. Datawarehousing
     - Apache Hive 
5. WorkFlow Management/Orchestration - Apache Airflow 
6. Microsoft Azure
7. Overall Knowledge- Data Modeling, ETL Pipeline

**Big data concepts:**

🔍 What is Big Data?
- 3 V's: Volume, Velocity, Variance
- Use Cases: Netflix, Flipkart, Amazon, eBay
- Challenges: Handling and processing vast amounts of data

💡 Technologies to Solve Big Data Problems:
- Hadoop
- Spark
- Kafka

📊 Hadoop Deep Dive:
Core Components:
- HDFS
- MapReduce
- YARN

📁 HDFS:
Daemons:
- NameNode
- DataNode
Architecture Overview

🔄 MapReduce:
Phases:
- Map Phase
- Reduce Phase
Process Steps

⚙️ YARN:
Components:
- Resource Manager
- Node Manager

Architecture:
- Resource Scheduler
- Application Manager

🗂️ Metadata

🍯 Hive Components:
- Metastore
- Driver
- Query Compiler
- Hive Server
