{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e91ee54-a403-4973-a5b7-7bc379db17da",
   "metadata": {},
   "source": [
    "1. Load the CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da4c428-ce68-4e63-942a-3f75a751ed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----+----------+------+-------------------+\n",
      "| id|        name| age|department|salary|          join_date|\n",
      "+---+------------+----+----------+------+-------------------+\n",
      "|  1|    John Doe|  29|        IT| 70000|2020-01-15 00:00:00|\n",
      "|  2|  Jane Smith|  34|        HR| 80000|2019-03-22 00:00:00|\n",
      "|  3| Bob Johnson|null|   Finance| 60000|2018-06-12 00:00:00|\n",
      "|  4| Alice White|  45|        IT|  null|2017-08-07 00:00:00|\n",
      "|  5| Chris Evans|  23|        HR| 50000|2021-05-19 00:00:00|\n",
      "|  6|        null|  31|   Finance| 75000|2020-11-01 00:00:00|\n",
      "|  7|  Mary Brown|  27|        IT| 72000|2018-09-30 00:00:00|\n",
      "|  8|James Wilson|  30|        HR| 85000|               null|\n",
      "+---+------------+----+----------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"PySparkProject\").getOrCreate()\n",
    "\n",
    "# Load CSV data\n",
    "df = spark.read.csv(\"data.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e68ac-dd0d-4103-a5d6-c4b45f225440",
   "metadata": {},
   "source": [
    "2. Data Cleaning\n",
    "\n",
    "Handle Missing Values: Replace missing values with appropriate defaults or drop rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a966b1-ee23-493e-b6ef-e59796f0dd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+----------+------+-------------------+\n",
      "| id|       name|age|department|salary|          join_date|\n",
      "+---+-----------+---+----------+------+-------------------+\n",
      "|  1|   John Doe| 29|        IT| 70000|2020-01-15 00:00:00|\n",
      "|  2| Jane Smith| 34|        HR| 80000|2019-03-22 00:00:00|\n",
      "|  3|Bob Johnson| 31|   Finance| 60000|2018-06-12 00:00:00|\n",
      "|  4|Alice White| 45|        IT|     0|2017-08-07 00:00:00|\n",
      "|  5|Chris Evans| 23|        HR| 50000|2021-05-19 00:00:00|\n",
      "|  7| Mary Brown| 27|        IT| 72000|2018-09-30 00:00:00|\n",
      "+---+-----------+---+----------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace missing age with the average age\n",
    "from pyspark.sql.functions import mean\n",
    "\n",
    "avg_age = df.select(mean(df['age'])).collect()[0][0]\n",
    "df = df.na.fill({'age': avg_age})\n",
    "\n",
    "# Replace missing salary with 0\n",
    "df = df.na.fill({'salary': 0})\n",
    "\n",
    "# Drop rows where name or join_date is missing\n",
    "df = df.na.drop(subset=[\"name\", \"join_date\"])\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1371eb6-45cf-40e7-82d2-d7c3139a6398",
   "metadata": {},
   "source": [
    "3. Data Validation\n",
    "\n",
    "Ensure Data Types: Check and enforce the correct data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45459976-fa48-42f7-a634-a12f12777b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: integer (nullable = false)\n",
      " |-- join_date: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: integer (nullable = false)\n",
      " |-- join_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "\n",
    "# Convert salary to integer if it's not already\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\"salary\", col(\"salary\").cast(\"integer\"))\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa62c1-7a31-4876-b712-a6d42b8ed747",
   "metadata": {},
   "source": [
    "Check for Duplicate Records: Remove duplicates if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ed6dbf-9af5-4988-a7cd-81cc142d80d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+----------+------+-------------------+\n",
      "| id|       name|age|department|salary|          join_date|\n",
      "+---+-----------+---+----------+------+-------------------+\n",
      "|  3|Bob Johnson| 31|   Finance| 60000|2018-06-12 00:00:00|\n",
      "|  2| Jane Smith| 34|        HR| 80000|2019-03-22 00:00:00|\n",
      "|  4|Alice White| 45|        IT|     0|2017-08-07 00:00:00|\n",
      "|  1|   John Doe| 29|        IT| 70000|2020-01-15 00:00:00|\n",
      "|  7| Mary Brown| 27|        IT| 72000|2018-09-30 00:00:00|\n",
      "|  5|Chris Evans| 23|        HR| 50000|2021-05-19 00:00:00|\n",
      "+---+-----------+---+----------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropDuplicates()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4530c38-4587-4b08-b7dc-6f35efe32dba",
   "metadata": {},
   "source": [
    "4. Data Transformation\n",
    "\n",
    "Create New Columns: Add a column for the year of joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7aa6e1e-2196-4fd7-a30a-9c2d73a828b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+----------+------+-------------------+---------+\n",
      "| id|       name|age|department|salary|          join_date|join_year|\n",
      "+---+-----------+---+----------+------+-------------------+---------+\n",
      "|  3|Bob Johnson| 31|   Finance| 60000|2018-06-12 00:00:00|     2018|\n",
      "|  2| Jane Smith| 34|        HR| 80000|2019-03-22 00:00:00|     2019|\n",
      "|  4|Alice White| 45|        IT|     0|2017-08-07 00:00:00|     2017|\n",
      "|  1|   John Doe| 29|        IT| 70000|2020-01-15 00:00:00|     2020|\n",
      "|  7| Mary Brown| 27|        IT| 72000|2018-09-30 00:00:00|     2018|\n",
      "|  5|Chris Evans| 23|        HR| 50000|2021-05-19 00:00:00|     2021|\n",
      "+---+-----------+---+----------+------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "df = df.withColumn(\"join_year\", year(df[\"join_date\"]))\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45cd0c-e307-420c-8bfe-317b19eae123",
   "metadata": {},
   "source": [
    "Group and Aggregate Data: Calculate the average salary by department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672b6e9b-4d96-48f9-ba89-ac5848b15295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|department|       avg(salary)|\n",
      "+----------+------------------+\n",
      "|        HR|           65000.0|\n",
      "|   Finance|           60000.0|\n",
      "|        IT|47333.333333333336|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_salary_df = df.groupBy(\"department\").avg(\"salary\")\n",
    "avg_salary_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691e979-a650-46c5-a3f7-e7f3f574170f",
   "metadata": {},
   "source": [
    "Filter Data: Find employees who joined after 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "469d4222-9c08-4003-8858-28629f01d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+----------+------+-------------------+---------+\n",
      "| id|       name|age|department|salary|          join_date|join_year|\n",
      "+---+-----------+---+----------+------+-------------------+---------+\n",
      "|  1|   John Doe| 29|        IT| 70000|2020-01-15 00:00:00|     2020|\n",
      "|  5|Chris Evans| 23|        HR| 50000|2021-05-19 00:00:00|     2021|\n",
      "+---+-----------+---+----------+------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recent_joins_df = df.filter(df[\"join_year\"] > 2019)\n",
    "recent_joins_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee401d1-cb02-40cd-90f6-d67c96eeea7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76747979-73e2-488c-9a1c-da58cc47e181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504f687-3b99-48c7-a65e-8e126cae2cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70032cf5-6609-4d98-844a-9474b21c149f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c3ad7e-4f69-4caf-8e49-98ff408695a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
